{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to tensors\n",
    "\n",
    "Creating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get tensor back as python int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector \n",
    "vector = torch.tensor([7,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape is 2 by one element \n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4, 5],\n",
       "         [5, 6]]),\n",
       " 2,\n",
       " torch.Size([2, 2]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX = torch.tensor([[4,5],[5,6]])\n",
    "MATRIX , MATRIX.ndim, MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 5, 4]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor\n",
    "TENSOR = torch.tensor([[[1,2,3],[3,6,9],[2,5,4]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2469, 0.9785, 0.8527, 0.4130],\n",
       "         [0.5435, 0.5213, 0.0630, 0.3616],\n",
       "         [0.3974, 0.5654, 0.6709, 0.9384]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (1,3,4)\n",
    "random_tensor = torch.rand(1,3,4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, torch.Size([1, 3, 4]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim, random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, torch.Size([224, 224, 3]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a random tensor with similear shape to an image\n",
    "random_image_size_tensor = torch.rand(size=(224,224,3))\n",
    "random_image_size_tensor.ndim, random_image_size_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([3, 4]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create all zeros tensor\n",
    "zeros = torch.zeros(size=(3,4))\n",
    "zeros.ndim, zeros.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([3, 4]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(size=(3,4))\n",
    "ones.ndim, ones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4, 6, 8])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use torch.range()\n",
    "# start, end, step\n",
    "ott = torch.arange(0,10,2)\n",
    "ott"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating tensors like another array\n",
    "tenzeros = torch.zeros_like(ott)\n",
    "tenzeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor = torch.tensor([3.0,6.0,9.0], dtype=None,\n",
    "                                              device=None,\n",
    "                                              requires_grad=False)\n",
    "float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16 = float_32_tensor.type(torch.float16)\n",
    "float_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16 * float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3,6,9], dtype=torch.int32) \n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor * int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3,6,9], dtype=torch.long)\n",
    "float_32_tensor * int_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Information From Tensors\n",
    "\n",
    "1. Get dataype tensor.dtype\n",
    "2. Get shape tensor.shape\n",
    "3. Get device tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Tensors (tensor operations)\n",
    "\n",
    "* Addition \n",
    "* Substraction\n",
    "* Multiplication(element-vise)\n",
    "* Division\n",
    "* Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([101, 102, 103])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor and add 10 to it\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply tensor by 10\n",
    "tensor*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(tensor,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Multiplication\n",
    "\n",
    "Two ways:\n",
    "1. Element Vise\n",
    "2. Matirx multiplication( dot product )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Element Vise\n",
    "tensor * tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.01 ms, sys: 72 μs, total: 1.08 ms\n",
      "Wall time: 2.87 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(14), tensor([1, 2, 3]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor), tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One of the most common erros in deep learning: shape errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8684, 0.9367],\n",
       "        [1.0374, 1.1320]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.matmul(torch.rand(3,2),torch.rand(3,2)) # Error\n",
    "torch.matmul(torch.rand(2,3),torch.rand(3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_A = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "torch_B = torch.tensor([[7,10],[8,11],[9,12]])\n",
    "\n",
    "# torch.matmul(torch_A,torch_B) # Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulate Shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor.T will transpose the matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 76, 103],\n",
       "        [100, 136]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch_A.T,torch_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the min, max , mean, sum, etc(tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]), torch.int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0, 100 , 10)\n",
    "x , x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find Min\n",
    "torch.min(x) , x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(90))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(45.))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.mean() require tensor of float32\n",
    "torch.mean(x.type(torch.float32)) , x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding positional min max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(9))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.argmin(), x.argmax()\n",
    "# Returns the index postion of the min , max element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping, Stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "* Reshaping - reshapes an input tensor to a defined shape\n",
    "* View - Return a an input tensosr of cetain shape but keep the same merory as the original tensor\n",
    "* stacking - combine multiple tensors on top of each other  or side by side (hstack)\n",
    "* squeeze - removes all '1' dimensions from tensor\n",
    "* Unsqueeze - add a '1' dimension to a target tensor\n",
    "* Permute - Return a view of the input with dimensions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1., 10.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "x_reshaped = x.reshape(1,9)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the view \n",
    "z = x.view(1,9)\n",
    "z, z.shape\n",
    "# here z shares the same memory as x so changing z means changing x or vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:, 0] =5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 5., 5.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [4., 4., 4., 4.],\n",
       "        [5., 5., 5., 5.],\n",
       "        [6., 6., 6., 6.],\n",
       "        [7., 7., 7., 7.],\n",
       "        [8., 8., 8., 8.],\n",
       "        [9., 9., 9., 9.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other \n",
    "x_stacked = torch.stack([x,x,x,x], dim =1) # or dim =0\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.squeeze() removes all the single dimensions from target tensor\n",
    "x_squeeze = torch.squeeze(x)\n",
    "x_squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_reshaped)\n",
    "x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped.squeeze(), x_reshaped.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]),\n",
       " torch.Size([9, 1]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.unsqueeze() add a single demension to a target tensor at a specific dimension\n",
    "x_reshaped.squeeze().unsqueeze(dim = 1), x_reshaped.squeeze().unsqueeze(dim = 1).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), torch.Size([224, 224, 3]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.permute() rearranges the dimensions of a target tensor in a specified order\n",
    "x_original = torch.rand(224,224,3) # [height, width, color]\n",
    "x_premute = x_original.permute(2, 0, 1) # [colour, height, width]\n",
    "x_premute.shape , x_original.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing (Selecting data from tensors)\n",
    "indexing with pytorch is similar to indexing with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch .arange(1,10).reshape(1,3,3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets index on our new tensor\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets index on the middle bracket (dim=1)\n",
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets index on the most inner bracket (last dimension)\n",
    "x[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can use : to select all of a target dimension\n",
    "x[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, : ,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all values of the 0 dim but only 1 index value of 1st and 2nd dimension\n",
    "x[:,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch tensors & NumPy\n",
    "Since NumPy is a popular Python numerical computing library, PyTorch has functionality to interact with it nicely.\n",
    "\n",
    "The two main methods you'll want to use for NumPy to PyTorch (and back again) are:\n",
    "\n",
    "* torch.from_numpy(ndarray) - NumPy array -> PyTorch tensor.\n",
    "* torch.Tensor.numpy() - PyTorch tensor -> NumPy array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]), tensor([1., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy array to tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "array = np.arange(1.0,8.0)\n",
    "tensor = torch.from_numpy(array).type(torch.float32)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), array([2., 3., 4., 5., 6., 7., 8.]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the value of array, what will this do to tensor?\n",
    "array = array +1\n",
    "tensor, array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4., 5., 6., 7.], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducbility (Trying to take random out of random)\n",
    "In short how a neural network learns:\n",
    "\n",
    "to reduce randomness variability we use random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8124, 0.3124, 0.8125, 0.2205],\n",
       "         [0.5376, 0.0601, 0.0825, 0.6946],\n",
       "         [0.1183, 0.7003, 0.5444, 0.4690]]),\n",
       " tensor([[0.0995, 0.2584, 0.6662, 0.7675],\n",
       "         [0.2328, 0.4033, 0.8491, 0.8117],\n",
       "         [0.6352, 0.5982, 0.3338, 0.3439]]))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "random_tensor_A = torch.rand (3,4)\n",
    "random_tensor_B = torch.rand (3,4)\n",
    "\n",
    "random_tensor_A , random_tensor_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets make some reproducable random seed\n",
    "import torch\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "random_tensor_c = torch.rand(3,4)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_d = torch.rand(3,4)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "random_tensor_c == random_tensor_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 18 16:10:05 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060        Off |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   31C    P8             16W /  170W |     633MiB /  12288MiB |      5%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A       947      G   /usr/lib/Xorg                                  15MiB |\n",
      "|    0   N/A  N/A      1048      G   /usr/bin/kwalletd6                              2MiB |\n",
      "|    0   N/A  N/A      1078      G   /usr/bin/kwin_wayland                          11MiB |\n",
      "|    0   N/A  N/A      1185      G   /usr/bin/Xwayland                              63MiB |\n",
      "|    0   N/A  N/A      1222      G   /usr/bin/ksmserver                              2MiB |\n",
      "|    0   N/A  N/A      1224      G   /usr/bin/kded6                                  2MiB |\n",
      "|    0   N/A  N/A      1238      G   /usr/bin/plasmashell                           68MiB |\n",
      "|    0   N/A  N/A      1295      G   /usr/lib/kactivitymanagerd                      2MiB |\n",
      "|    0   N/A  N/A      1300      G   /usr/bin/gmenudbusmenuproxy                     2MiB |\n",
      "|    0   N/A  N/A      1301      G   /usr/bin/kaccess                                2MiB |\n",
      "|    0   N/A  N/A      1303      G   ...b/polkit-kde-authentication-agent-1          2MiB |\n",
      "|    0   N/A  N/A      1304      G   /usr/lib/org_kde_powerdevil                     2MiB |\n",
      "|    0   N/A  N/A      1305      G   /usr/lib/xdg-desktop-portal-kde                 2MiB |\n",
      "|    0   N/A  N/A      1306      G   /usr/bin/xembedsniproxy                         2MiB |\n",
      "|    0   N/A  N/A      1403      G   /usr/bin/kdeconnectd                            2MiB |\n",
      "|    0   N/A  N/A      1473      G   /usr/bin/xwaylandvideobridge                    2MiB |\n",
      "|    0   N/A  N/A      1795      G   /usr/lib/baloorunner                            2MiB |\n",
      "|    0   N/A  N/A      1892      G   ...erProcess --variations-seed-version        117MiB |\n",
      "|    0   N/A  N/A      4772      G   /opt/google/chrome/chrome                       2MiB |\n",
      "|    0   N/A  N/A      4818      G   ...seed-version=20241217-180204.362000         68MiB |\n",
      "|    0   N/A  N/A      5014      G   ...bin/plasma-browser-integration-host          2MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "## Running tensors and pytorch on the GPUs\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of GPUs\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting tensors(and models) on the GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), device(type='cpu'))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "\n",
    "tensor, tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "All of the exercises are focused on practicing the code above.\n",
    "\n",
    "You should be able to complete them by referencing each section or by following the resource(s) linked.\n",
    "\n",
    "Resources:\n",
    "\n",
    "Exercise template notebook for 00.\n",
    "Example solutions notebook for 00 (try the exercises before looking at this).\n",
    "1. Documentation reading - A big part of deep learning (and learning to code in general) is getting familiar with the documentation of a certain framework you're using. We'll be using the PyTorch documentation a lot throughout the rest of this course. So I'd recommend spending 10-minutes reading the following (it's okay if you don't get some things for now, the focus is not yet full understanding, it's awareness). See the documentation on torch.Tensor and for torch.cuda.\n",
    "2. Create a random tensor with shape (7, 7).\n",
    "3. Perform a matrix multiplication on the tensor from 2 with another random tensor with shape (1, 7) (hint: you may have to transpose the second tensor).\n",
    "4. Set the random seed to 0 and do exercises 2 & 3 over again.\n",
    "5. Speaking of random seeds, we saw how to set it with torch.manual_seed() but is there a GPU equivalent? (hint: you'll need to look into the documentation for torch.cuda for this one). If there is, set the GPU random seed to 1234.\n",
    "6. Create two random tensors of shape (2, 3) and send them both to the GPU (you'll need access to a GPU for this). Set torch.manual_seed(1234) when creating the tensors (this doesn't have to be the GPU random seed).\n",
    "7. Perform a matrix multiplication on the tensors you created in 6 (again, you may have to adjust the shapes of one of the tensors).\n",
    "8. Find the maximum and minimum values of the output of 7.\n",
    "9. Find the maximum and minimum index values of the output of 7.\n",
    "10. Make a random tensor with shape (1, 1, 1, 10) and then create a new tensor with all the 1 dimensions removed to be left with a tensor of shape (10). Set the seed to 7 when you create it and print out the first tensor and it's shape as well as the second tensor and it's shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3227, 0.0162, 0.2137, 0.6249, 0.4340, 0.1371, 0.5117],\n",
       "         [0.1585, 0.0758, 0.2247, 0.0624, 0.1816, 0.9998, 0.5944],\n",
       "         [0.6541, 0.0337, 0.1716, 0.3336, 0.5782, 0.0600, 0.2846],\n",
       "         [0.2007, 0.5014, 0.3139, 0.4654, 0.1612, 0.1568, 0.2083],\n",
       "         [0.3289, 0.1054, 0.9192, 0.4008, 0.9302, 0.6558, 0.0766],\n",
       "         [0.8460, 0.3624, 0.3083, 0.0850, 0.0029, 0.6431, 0.3908],\n",
       "         [0.6947, 0.0897, 0.8712, 0.1330, 0.4137, 0.6044, 0.7581]]),\n",
       " torch.Size([7, 7]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 2:\n",
    "random_tensor = torch.rand(7,7)\n",
    "random_tensor , random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.9694],\n",
       "         [0.8496],\n",
       "         [1.0770],\n",
       "         [1.1261],\n",
       "         [1.3105],\n",
       "         [1.5322],\n",
       "         [1.3691]]),\n",
       " torch.Size([7, 1]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 3:\n",
    "Ans_Matrix = torch.matmul(random_tensor,torch.rand(1,7).T)\n",
    "Ans_Matrix, Ans_Matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6511, 0.7745, 0.4369, 0.5191, 0.6159, 0.8102, 0.9801],\n",
      "        [0.1147, 0.3168, 0.6965, 0.9143, 0.9351, 0.9412, 0.5995],\n",
      "        [0.0652, 0.5460, 0.1872, 0.0340, 0.9442, 0.8802, 0.0012],\n",
      "        [0.5936, 0.4158, 0.4177, 0.2711, 0.6923, 0.2038, 0.6833],\n",
      "        [0.7529, 0.8579, 0.6870, 0.0051, 0.1757, 0.7497, 0.6047],\n",
      "        [0.1100, 0.2121, 0.9704, 0.8369, 0.2820, 0.3742, 0.0237],\n",
      "        [0.4910, 0.1235, 0.1143, 0.4725, 0.5751, 0.2952, 0.7967]]) torch.Size([7, 7])\n",
      "tensor([[2.4911],\n",
      "        [2.1696],\n",
      "        [1.5092],\n",
      "        [1.6439],\n",
      "        [2.3490],\n",
      "        [1.4221],\n",
      "        [1.1739]]) torch.Size([7, 1])\n"
     ]
    }
   ],
   "source": [
    "# Question 4:\n",
    "torch.manual_seed(0)\n",
    "random_tensor = torch.rand(7,7)\n",
    "print(random_tensor , random_tensor.shape)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "Ans_Matrix = torch.matmul(random_tensor,torch.rand(1,7).T)\n",
    "print(Ans_Matrix, Ans_Matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5:\n",
    "torch.cuda.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1272, 0.8167, 0.5440],\n",
       "         [0.6601, 0.2721, 0.9737]], device='cuda:0'),\n",
       " torch.Size([2, 3]),\n",
       " tensor([[0.1272, 0.8167, 0.5440],\n",
       "         [0.6601, 0.2721, 0.9737]], device='cuda:0'),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 6:\n",
    "torch.cuda.manual_seed(1234)\n",
    "tensor_one = torch.rand(2,3,device=\"cuda\")\n",
    "torch.cuda.manual_seed(1234)\n",
    "tensor_two = torch.rand(2,3,device=\"cuda\")\n",
    "tensor_one , tensor_one.shape, tensor_two, tensor_two.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.9792, 0.8358],\n",
       "         [0.8358, 1.4578]], device='cuda:0'),\n",
       " torch.Size([2, 2]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 7:\n",
    "gpu_mutiply_matrix = torch.matmul(tensor_one, tensor_two.T)\n",
    "gpu_mutiply_matrix, gpu_mutiply_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.4578, device='cuda:0'), tensor(0.8358, device='cuda:0'))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 8:\n",
    "gpu_mutiply_matrix.max(), gpu_mutiply_matrix.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3, device='cuda:0'), tensor(1, device='cuda:0'))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 9:\n",
    "gpu_mutiply_matrix.argmax(), gpu_mutiply_matrix.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.9546, 0.4950, 0.9420, 0.5926, 0.6996, 0.2087, 0.6753, 0.4810,\n",
       "            0.6333, 0.5733]]]], device='cuda:0'),\n",
       " torch.Size([1, 1, 1, 10]),\n",
       " tensor([0.9546, 0.4950, 0.9420, 0.5926, 0.6996, 0.2087, 0.6753, 0.4810, 0.6333,\n",
       "         0.5733], device='cuda:0'),\n",
       " torch.Size([10]))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 10:\n",
    "torch.cuda.manual_seed(7)\n",
    "random_tensor_n = torch.rand(1,1,1,10,device=\"cuda\")\n",
    "random_tensor_squeezed = random_tensor_n.squeeze()\n",
    "random_tensor_n, random_tensor_n.shape, random_tensor_squeezed, random_tensor_squeezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
